{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "#etl class\n",
        "class ETLProcessor:\n",
        "  def __init__(self, db_name='etl_data.db'):\n",
        "        self.conn = sqlite3.connect(db_name)\n",
        "\n",
        "#retrieves the temperature (celsius), precipitation (in inches), and precipitation type for a given latitude, longitude, and date\n",
        "  def fetch_historical_weather(self,lat, lon, start_date):\n",
        "    try:\n",
        "      weather_url = f'https://archive-api.open-meteo.com/v1/archive?latitude={lat}&longitude={lon}&start_date={start_date}&end_date={start_date}&daily=temperature_2m_max,temperature_2m_min,precipitation_sum,weathercode&timezone=auto'\n",
        "      response = requests.get(weather_url)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()\n",
        "      daily = data.get('daily', {})\n",
        "      temp_max = daily.get('temperature_2m_max', [None])[0]\n",
        "      temp_min = daily.get('temperature_2m_min', [None])[0]\n",
        "      precipitation = daily.get('precipitation_sum', [None])[0]\n",
        "      weather_code = daily.get('weathercode', [None])[0]\n",
        "      precipitation_type = self.get_precipitation_type(weather_code)\n",
        "      return {'temp_max': temp_max, 'temp_min': temp_min, 'precipitation': precipitation, 'precipitation_type': precipitation_type}\n",
        "    except Exception as e:\n",
        "      print(f\"Error fetching weather data: {e}\")\n",
        "\n",
        "      return {'temp_max': None, 'temp_min': None, 'precipitation': None, 'precipitation_type': None}\n",
        "\n",
        " #helper function for to get the type of precipitation based on codes used by open-meteo\n",
        "  def get_precipitation_type(self, weather_code):\n",
        "    precipitation_types = {0: 'Clear', 1: 'Mainly Clear', 2: 'Partly Cloudy', 3: 'Cloudy',\n",
        "            45: 'Fog', 48: 'Depositing Rime Fog', 51: 'Drizzle', 53: 'Drizzle', 55: 'Drizzle',\n",
        "            61: 'Rain', 63: 'Rain', 65: 'Rain', 66: 'Freezing Rain', 67: 'Freezing Rain',\n",
        "            71: 'Snow', 73: 'Snow', 75: 'Snow', 77: 'Snow Grains', 80: 'Rain Showers',\n",
        "            81: 'Rain Showers', 82: 'Rain Showers', 85: 'Snow Showers', 86: 'Snow Showers',\n",
        "            95: 'Thunderstorm', 96: 'Thunderstorm with Hail', 99: 'Thunderstorm with Hail'}\n",
        "    return precipitation_types.get(weather_code, 'Unknown')\n",
        "\n",
        " #loads the car accident csv data and picks a random sample of 100 car accidents\n",
        "  def load_accident_data(self,file_path):\n",
        "    try:\n",
        "      if file_path.lower().endswith('.csv'):\n",
        "        accident_data = pd.read_csv(file_path)\n",
        "      elif file_path.lower().endswith('.json'):\n",
        "        accident_data = pd.read_json(file_path)\n",
        "      else:\n",
        "        print(f\"Unsupported file format: {file_path}\")\n",
        "        return pd.DataFrame()\n",
        "      random_sample = accident_data.sample(n=100, random_state=42)\n",
        "      return random_sample\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading CSV file: {e}\")\n",
        "      return pd.DataFrame()\n",
        "#function that summarizes the ingested data (csv and json via api) by finding the number of rows and columns\n",
        "  def summarize_data_raw(self, data, label=\"Raw Data\"):\n",
        "    \"\"\"\n",
        "    Prints a summary (number of records and columns) of the provided DataFrame.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      num_records = len(data)\n",
        "      num_columns = len(data.columns)\n",
        "      print(f\"{label} Summary: {num_records} records and {num_columns} columns.\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error summarizing {label}: {e}\")\n",
        "\n",
        "  def transform_merge_data(self, accident_data):\n",
        "    try:\n",
        "      #converts the start time column in the csv to just the date instead of the date and time\n",
        "      accident_data['Start_Time'] = pd.to_datetime(accident_data['Start_Time'], errors='coerce').dt.date\n",
        "      #drops any records with empty start dates\n",
        "      accident_data = accident_data.dropna(subset=['Start_Time']).copy()\n",
        "      temps_max, temps_min, precipitations, precipitation_types = [], [], [], []\n",
        "      #fetches the weather data from the api with the given latitude, longitude, and date of a record in the csv\n",
        "      for index, row in accident_data.iterrows():\n",
        "        weather_data = self.fetch_historical_weather(row['Start_Lat'], row['Start_Lng'], row['Start_Time'])\n",
        "        temps_max.append(weather_data['temp_max'])\n",
        "        temps_min.append(weather_data['temp_min'])\n",
        "        precipitations.append(weather_data['precipitation'])\n",
        "        precipitation_types.append(weather_data['precipitation_type'])\n",
        "        time.sleep(0.2)\n",
        "      #turns the weather data into a csv that can be summarized by finding the number of rows and columns\n",
        "      raw_weather_df = pd.DataFrame({\n",
        "           \"temp_max\": temps_max,\n",
        "           \"temp_min\": temps_min,\n",
        "           \"precipitation\":precipitations,\n",
        "           \"precipitation_type\": precipitation_types\n",
        "            })\n",
        "\n",
        "      self.summarize_data_raw(raw_weather_df, label=\"Raw Weather Data\")\n",
        "      print()\n",
        "\n",
        "      #appends this information to the csv\n",
        "      accident_data['weather_temp_max'] = temps_max\n",
        "      accident_data['weather_temp_min'] = temps_min\n",
        "      accident_data['weather_precipitation'] = precipitations\n",
        "      accident_data['weather_precipitation_type'] = precipitation_types\n",
        "\n",
        "      print(f'Data Transformed: {len(accident_data)} records and {len(accident_data.columns)} columns')\n",
        "      print()\n",
        "      return accident_data\n",
        "    except Exception as e:\n",
        "      print(f\"Error transforming data: {e}\")\n",
        "      return pd.DataFrame()\n",
        "  #loads the information from the csv into a table in a SQLite data base\n",
        "  def load_data(self, transformed_data, table_name = 'accident_weather'):\n",
        "    try:\n",
        "      transformed_data.to_sql(table_name, self.conn, if_exists='replace', index=False)\n",
        "      print(f'Data Loaded: {len(transformed_data)} records and {len(transformed_data.columns)} columns')\n",
        "      print()\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading data: {e}\")\n",
        "  #based on user input the transformed data can be given as a csv or json along with being loaded into the database\n",
        "  def desired_output_format(self, transformed_data, format, output_file):\n",
        "    try:\n",
        "      if format == 'json':\n",
        "        return transformed_data.to_json(f'{output_file}.json',orient='records')\n",
        "        print()\n",
        "      elif format == 'csv':\n",
        "        return transformed_data.to_csv(f'{output_file}.csv', index=False)\n",
        "        print()\n",
        "      elif format == 'sql':\n",
        "        self.load_data(transformed_data, table_name = output_file)\n",
        "        print(f'Data converted and saved as {output_file}.{format}')\n",
        "        print()\n",
        "      else:\n",
        "        print(f\"Unsupported output format: {format}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error generating desired output: {e}\")\n",
        "  #the data now loaded into the table is analyzed for correlations\n",
        "  def analyze_data(self, table_name='accident_weather'):\n",
        "    try:\n",
        "      #queries the table for frequency of car accidents based on precipitation type and prints out the chart\n",
        "      precipitation_query = f'''\n",
        "        SELECT weather_precipitation_type, COUNT(*) AS accident_count\n",
        "        FROM {table_name}\n",
        "        GROUP BY weather_precipitation_type\n",
        "        ORDER BY accident_count DESC\n",
        "        '''\n",
        "      precipitation_analysis = pd.read_sql(precipitation_query, self.conn)\n",
        "      print('Accident Frequency by Precipitation Type:')\n",
        "      print(precipitation_analysis)\n",
        "      print()\n",
        "      print()\n",
        "      #queries the table for frequency of car accidents based on maximum temperature and prints out the chart\n",
        "      temp_query = f'''\n",
        "        SELECT weather_temp_max, COUNT(*) AS accident_count\n",
        "        FROM {table_name}\n",
        "        GROUP BY weather_temp_max\n",
        "        ORDER BY accident_count DESC\n",
        "        '''\n",
        "      temp_analysis = pd.read_sql(temp_query, self.conn)\n",
        "      print('Accident Frequency by Temperature:')\n",
        "      print(temp_analysis)\n",
        "      print()\n",
        "      print(\"*\" * 40)\n",
        "      print()\n",
        "    except Exception as e:\n",
        "      print(f\"Error analyzing data: {e}\")\n",
        "  #summarizes the table in the database by finding the number of rows and columns\n",
        "  def summarize_data_transformed(self, table_name = 'accidents_weather'):\n",
        "    try:\n",
        "      query = f'SELECT COUNT(*) as num_records FROM {table_name}'\n",
        "      records = pd.read_sql(query, self.conn)['num_records'][0]\n",
        "\n",
        "      query = f'PRAGMA table_info({table_name})'\n",
        "      columns = len(pd.read_sql(query, self.conn))\n",
        "\n",
        "      print(f'Table \"{table_name}\" summary: {records} records and {columns} columns.')\n",
        "    except Exception as e:\n",
        "      print(f'Error summarizing table: {e}')\n",
        "  #closes connection to db\n",
        "  def close_connection(self):\n",
        "        self.conn.close()\n",
        "\n",
        "def main():\n",
        "  #prompts user for the name and type of the output file\n",
        "  output_format = input(\"Enter output file format (json, csv, or sql): \").strip().lower()\n",
        "  output_file = input(\"Enter desired output file name or SQL table name: \")\n",
        "  accident_file_path = 'USA_ACCIDENTS.csv'\n",
        "\n",
        "  print()\n",
        "  print(\"*\" * 40)\n",
        "  print()\n",
        "  #declares a new ETLProcessor\n",
        "  etl = ETLProcessor()\n",
        "  #loads csv data\n",
        "  accident_data = etl.load_accident_data(accident_file_path)\n",
        "  if accident_data.empty:\n",
        "    print(\"No data loaded. Exiting...\")\n",
        "    return\n",
        "  #summarizes the raw csv data\n",
        "  etl.summarize_data_raw(accident_data, label=\"Raw Accident Data\")\n",
        "  print()\n",
        "  #transforms and merges csv with api data\n",
        "  transformed_data = etl.transform_merge_data(accident_data)\n",
        "  if transformed_data.empty:\n",
        "      print(\"Error during data transformation. Exiting.\")\n",
        "      return\n",
        "\n",
        "\n",
        "  print()\n",
        "  #loads data to sql database, summarizes the table and analyzes it\n",
        "  if output_format == \"sql\":\n",
        "    etl.desired_output_format(transformed_data, output_format, output_file)\n",
        "    print(\"*\" * 40)\n",
        "    print()\n",
        "    etl.summarize_data_transformed(table_name=output_file)\n",
        "    print()\n",
        "    etl.analyze_data(table_name= output_file)\n",
        "    #etl.summarize_data_transformed(table_name=\"accident_weather\")\n",
        "\n",
        "  else:\n",
        "      etl.desired_output_format(transformed_data, output_format, output_file)\n",
        "      print(\"*\" * 40)\n",
        "      print()\n",
        "      etl.load_data(transformed_data,output_file)\n",
        "      etl.summarize_data_transformed(output_file)\n",
        "      print()\n",
        "      etl.analyze_data(output_file)\n",
        "\n",
        "\n",
        " #closes connection to db\n",
        "  etl.close_connection()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nD5dsuMHRxPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa58737-3c62-41a5-b86f-1eb054e6b411"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter output file format (json, csv, or sql): json\n",
            "Enter desired output file name or SQL table name: accident_weather\n",
            "\n",
            "****************************************\n",
            "\n",
            "Raw Accident Data Summary: 100 records and 8 columns.\n",
            "\n",
            "Raw Weather Data Summary: 92 records and 4 columns.\n",
            "\n",
            "Data Transformed: 92 records and 12 columns\n",
            "\n",
            "\n",
            "****************************************\n",
            "\n",
            "Data Loaded: 92 records and 12 columns\n",
            "\n",
            "Table \"accident_weather\" summary: 92 records and 12 columns.\n",
            "\n",
            "Accident Frequency by Precipitation Type:\n",
            "  weather_precipitation_type  accident_count\n",
            "0                     Cloudy              29\n",
            "1                    Drizzle              27\n",
            "2                       Rain              16\n",
            "3                       Snow               7\n",
            "4               Mainly Clear               7\n",
            "5                      Clear               6\n",
            "\n",
            "\n",
            "Accident Frequency by Temperature:\n",
            "    weather_temp_max  accident_count\n",
            "0               29.2               2\n",
            "1               28.7               2\n",
            "2               27.6               2\n",
            "3               26.1               2\n",
            "4               22.8               2\n",
            "..               ...             ...\n",
            "75               1.7               1\n",
            "76               1.0               1\n",
            "77               0.6               1\n",
            "78              -0.2               1\n",
            "79              -1.2               1\n",
            "\n",
            "[80 rows x 2 columns]\n",
            "\n",
            "****************************************\n",
            "\n"
          ]
        }
      ]
    }
  ]
}